# 面试复习

## 一、非业务问题

### 1、为什么想要跳槽

* 需求没有重大革新，运营驱动，缺少活力
* 公司的上升前景太小，职级，薪资，员工关怀都不行
* 技术氛围不好，不脚踏实地。

## 二、技术问题

### 1、kafka

#### 1)、ISR机制

如上文所述，`kafka`一个`partiton`会有多个`replication`,其中会有一个`leader`和多个`follower`。

`ISR`是指，能够和`leader`保持同步的`follower` 。关键参数`replica.lag.time.max.ms` 默认10秒，含义为在10秒内`follower`曾经追赶上`leader`，否则被剔除`ISR`.(为什么不是心跳检测？因为如果消息落后太多也是没有意义的)。

一般有两个副本失效原因:`follower`进程卡住没有向`leader`请求同步，比如频繁`fullgc`;`follower`副本进程同步过慢无法赶上，例如`IO`开销过大。

### 2、JVM

#### 1）、内存分布

分为堆、程序计数器、虚拟机栈、本地方法栈、元空间、直接内存。

* 程序计数器：程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成
* Java 虚拟机栈：方法调用的数据需要通过栈进行传递，每一次方法调用都会有一个对应的栈帧被压入栈中，每一个方法调用结束后，都会有一个栈帧被弹出。栈由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法返回地址。
* 本地方法栈：同上
* 堆：几乎所有的对象实例以及数组都在这里分配内存、字符串常量池
* 元空间：类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据。运行时常量池

#### 2）、垃圾回收

**堆分类**

分为Eden、S1、S0、Tenured 、metaspace

对象优先在 Eden 区分配、大对象直接进入老年代、长期存活的对象将进入老年代

```
“Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 survivor 区的 50% 时（默认值是 50%，可以通过 -XX:TargetSurvivorRatio=percent 来设置），取这个年龄和 MaxTenuringThreshold 中更小的一个值，作为新的晋升年龄阈值”
```

**GC分类**

部分收集 (Partial GC)：

- 新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集；
- 老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集；
- 混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。

整堆收集 (Full GC)：收集整个 Java 堆和方法区

**死亡对象判断方法**

* 引用计数法(会有循环引用的问题)

* 可达性分析

虚拟机栈、本地方法栈中引用的对象、所有被同步锁持有的对象、类静态属性引用的对象、常量引用的对象可以作为GC root

要真正宣告一个对象死亡，至少要经历两次标记过程

**引用类型**

* 强引用：垃圾回收器绝不会回收它
* 软引用：如果内存空间足够，垃圾回收器就不会回收它
* 弱引用：在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存
* 虚引用：任何时候都可能被垃圾回收、虚引用主要用来跟踪对象被垃圾回收的活动

**垃圾收集算法**

* 标记清除：空间碎片
* 标记复制：内存利用率低
* 标记整理

**垃圾收集器**

|    垃圾收集器     |   类型   |    作用域     | 使用算法 |     特点     |
| :---------------: | :------: | :-----------: | :------: | :----------: |
|      Serial       |   串行   |    新生代     | 标记复制 | 响应速度优先 |
|    Serial old     |   串行   |    老年代     | 标记整理 | 响应速度优先 |
|      ParNew       |   并行   |    新生代     | 标记复制 | 响应速度优先 |
| Parallel Scavenge |   并行   |    新生代     | 标记复制 |  吞吐量优先  |
|   Parallel old    |   并行   |    老年代     | 标记整理 |  吞吐量优先  |
|        CMS        |   并发   |    老年代     | 标记清楚 | 响应速度优先 |
|        G1         | 并行并发 | 老年代&老年代 |          |              |

还在使用的组合Serial+Serial Old, Parallel Scavenge + Parallel old, ParNew + CMS，G1



## Mysql数据库

### InnoDB的事务管理以及MVCC

变化的老版本行数据被存在一个叫`rollback segment`的系统表空间中，用于支持并发事务和回滚等场景。  
在内部，InnoDB会为每一行额外添加三个隐藏字段：
`DB_TRX_ID` :6-byte，表示插入或者更新这行数据的最后的txn_id，在内部delete操作被视为update  
`DB_ROLL_PTR`: 7-byte,回滚指针，指向`undo log`中更新前的记录的数据位置  
`DB_ROW_ID` 6-byte,如果没有指定主键，则会作为主键使用，也会作为聚簇索引的一部分，如果指定了主键就不会作为聚簇索引的一部分  

`undo log`分为`insert undo log`和`update undo log`,前者只用于事务回滚，当事务提交之后就可以丢弃。后者还用于了`consistent read`中，当没有事务需要修改之前（旧版本）的这条数据的快照时，可以将其丢弃。

当执行delete语句时，数据并不会马上被删除，而是被标记。然后通过`purge`线程清理被标记为要删除的`update undo log`,这是数据才被真正的删除。  
二级索引的列，是没有隐藏的字段的。当一个旧的二级索引列被更新时，它会被标记为删除，最终被purge线程清理掉，新的数据会被插入。
当一个二级索引列的数据被一个新的事务更新或者删除，InooDB会先去找聚簇索引，然后从`undo log`中找到旧的快照数据，用于给在此期间的其他读事务使用。  

InnoDB主要有两种类型的行锁，共享锁(shared lock)和排他锁(exclusive lock)
共享锁用于一个事务使用一个锁进行读取，可以多个事务同时持有一个共享锁。排他锁用于一个事务使用一个锁进行更新或者删除，同一时间只能有一个事务持有排他锁。

### 快照读与当前读

* 快照读（Consistent Read）

  就是单纯的 SELECT 语句，通过 undo log + MVCC 来实现。返回当前事务可见的快照版本数据

* 当前读

  SELECT ... FOR UPDATE 、SELECT ... LOCK IN SHARE MODE或者是修改语句，通过 next-key lock实现的。返回最新数据

### 锁

**锁的实现是基于索引实现的，锁住的就是命中的索引节点** （好好体会！）

基于锁的属性分类：共享锁、排他锁。

基于锁的粒度分类：表锁、行锁(记录锁（record lock）、间隙锁（gap lock）、临键锁（next key lock）)。

基于锁的状态分类：意向共享锁、意向排它锁。

#### 共享锁（share lock）

当一个事务为数据加上共享锁(也称为读锁)之后，其他事务只能对该数据加读锁，而不能对数据加写锁。

在查询语句后面加`LOCK IN SHARE MODE`

#### 排他锁（exclusive lock）

当一个事务为数据加上排他锁(也称为写锁)之后，其他请求将不能再为数据加任何锁。

在查询语句后面加`for update`或是修改语句

#### 表锁

表不加索引对数据修改时

#### 记录锁（record lock）

当在where条件中是**唯一索引**且**能找到**匹配行时，会对这行加上行锁。

如果这条记录没有索引,会对默认生成的聚簇索引即row id 添加`Record Lock`

#### 间隙锁（gap lock）

当查询条件没有命中索引或者是没有命中唯一索引（及where条件**是有可能**会返回多条的情况），则会被上间隙锁。**RR级别** （RC级别会用做检查唯一索引和外键）

#### 临键锁（next-key lock）

Next-Key Locks是一个在索引记录上的Record Lock和在这个索引记录之前（到前一个符合搜索条件的索引记录，或者是负无穷）的gap的Gap Lock的结合。RR级别。可以防止幻读行（phantom rows）

​	特殊情况：

* 唯一索引上的命中的等值查询会退化为行锁
* 索引上的等值查询--向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁
* 唯一索引上的范围查询会访问到不满足条件的第一个值为止

间隙锁是**左开右闭**的。例如

| id 唯一索引 | c普通索引 | d无索引 |
| :---------: | :-------: | :-----: |
|      5      |     5     |    5    |
|     10      |    10     |   10    |
|     15      |    15     |   15    |
|     20      |    20     |   20    |

```mysql
begin;
select * from t where id = 11 for update
commit;
# 增加（10，15]next-key lock，因为是索引上的等值查询退化为（10，15）

begin;
select id form t where c = 5 lock in share mode;
commit;
# 增加（-∞，5]和（5，10]next-key lock ，因为是索引上的等值查询退化为（-∞，5]和（5，10）

begin;
select * form t where id >= 10 and id <11 for update	
commit;
#增加（5，10]和(10,15],因为10是唯一索引且命中，退化为[10],(10,15]

begin;
select * form t where c >= 10 and c <11 for update
commit;
#增加（5，10]和(10,15]

#如果无索引，基本等于锁表
```



#### 意向锁（intensive lock）

意向锁是一个**表锁**，是为了支持多粒度的行锁与表锁共存而产生的。主要用于判断当前表或者表中的行是否有锁或者是否正在进行加锁，以避免进行全表的查询。
有两种：`intention shared lock（is）`(意向共享锁)和`intention exclusive lock(ix)`(意向排他锁)
**想要在行上获取共享锁，要先获得意向共享锁;想要在行上获取排他锁，要先获得意向排他锁。**

下表为兼容矩阵，所有的锁都表示**表锁！**

|  -   |    X     |     IX     |     S      |     IS     |
| :--: | :------: | :--------: | :--------: | :--------: |
|  X   | Conflict |  Conflict  |  Conflict  |  Conflict  |
|  IX  | Conflict | Compatible |  Conflict  | Compatible |
|  S   | Conflict |  Conflict  | Compatible | Compatible |
|  IS  | Conflict | Compatible | Compatible | Compatible |

* 意向锁之间都是兼容的
* 意向锁存在的意义是为了更高效的判断是否可以获取表锁

> 例如：如果表加了一个行排他锁，那先会加一个意向排他锁。所以此时要加表意向排他锁时，就无需一行行查看是否有行排他锁，只要看是否有表意向排他锁即可判断



## JVM调优

### CPU高如何排查

0、保留现场 

1、`top`查看消耗CPU高的进程pid

2、`top -H -p` 根据pid找出消耗高的线程号

3、将这个线程号转换为16进制

4、`jstack pid` 找到这个线程号对应调用堆栈

5、在堆栈信息中找出代码所在位置，分析代码

### 内存消耗高如何排查

1、`top`查看消耗内存高的进程pid。

2、`jmap`获取dump文件。

3、查看占用类型。

4、如果内存占用超过 -xmx，考虑元空间或者直接内存



## RabbitMq与Kafka的比较

1、消息顺序性，rabbitmq在多个consumer消费同一个queue时无法保证顺序，而kafka的partition是有序的，可以使用单个消费者消费单个partition。

2、rabbitmq路由更加灵活

3、kafka吞吐量更好

4、ranbbitmq消息可以支持延迟队列和时效性

5、持久化，kafka天然持久，而rabbitmq ack就没了

6、rabbitmq天然有死信队列,重试机制

7、消费者扩容缩小简单，比如向下缩减，partition就很难，消费者实现简单

## 接到一份需求如何开始工作

### 需求分析

明确目标试什么！最快还是资源占用最少还是要到达多少tps，确定排期

了解要实现什么功能，业务规则，业务流程，原型图等。在此基础下，记录需求中的疑问点，开会进行需求讨论。  

进行领域建模，确定有哪些实体，细化会有哪些行为

在开会中，确认要对接的系统，以及相应系统的接口是否需要重新开发，如果不需要则索要接口文档。

确认系统联调人员和开通网络等。

### 系统设计

比如分为多少个服务，每个服务中的泳道图，考虑所使用的技术等。

设计数据模型，e-r图，确定实体，之间的关联，有哪些属性。细化sql的行为，确定索引。  

### 功能测试

### 上线

## HashMap底层原理

### 结构

Node数组 + 链表或者红黑树

数组默认初始大小16，每次扩容增加一倍，都是2的幂次方个容量

负载因子0.75

### put

1、将对象的hashcode再进行一次hash (异或高16位与低16位) ，这样当数组长度比较好的时候可以获得更好的散列值

2、与数组长度减1（最大索引值）进行按位与，获得所要落到的数组的位置上，如果空直接放入。

3、如果hash冲突，则放到链表的最后，如果这时候长度大于等于8，转化为红黑树。

## Java锁

### Synchronized

java对象大致可以分为三个部分，分别是**对象头**、**实例变量**和**填充字节**

* 对象头： 主要分为MarkWord和KlassPoint，后者指向类元数据表明这个对象是哪个类的实例，前者存储运行时数据（包括hashcode，gc信息，锁信息）
* 实例变量：对象属性
* 填充字节：用于凑齐对象8字节的整数倍

Synchronized的锁标志就在MarkWord中，它存储了一个**重量级监视器锁的指针**，指向一个对象的监视器（monitor）锁对象。

要先获取这个锁对象才能获得找个对象

修饰代码块：**monitorentry**和**monitorexit**

修饰方法：方法标志**ACC_SYNCHRONIZED**

### 偏向锁

对象不会主动释放锁，查看当前线程与对象头中的线程是否一致，如果一致无需加锁减锁。如果不一致，查看那个线程是否存活。不存活，恢复无锁状态重新竞争偏向锁，如果存活，查看该线程是否还需要该对象，还需要，升级轻量级锁，不再使用，恢复为无锁重新竞争。

### 轻量级锁

也就是不阻塞线程，避免cpu从用户态转为内核态，使用自旋，适用竞争少，加锁时间短。

### 重量级锁

如果自旋次数超过一定次数，或者在自旋的时候，来了第三个线程，就会变为重量级锁

除了偏向锁可以重置为无锁，其他都无法降级。

### ReentrantLock

api层面

ReentrantLock基于AQS实现，而AQS底层使用的是改进的CLH队列，CAS+阻塞+唤醒，对于暂时获取不到资源以及尚未被父节点唤醒的线程在队列中阻塞休眠，被唤醒后CAS获取资源。并不是单纯的阻塞或者CAS，兼顾了性能和效率

等待可中断，公平非公平通过，通过aqs+cas

## Redis

### 分布式锁算法

```lua
SET resource_name my_random_value NX PX 30000
```

value可以是包含当前线程号的随机值。

```
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

### RedLock

1、获取当前时间（ms)

2、依次获取5台实例上的锁，同样的key随机的value，并设置一个远小于锁过期时间的加锁超时时间（几百上千倍）

3、只有获得多数ack以及在规定时间内完成才会被认为获取到锁

4、过期时间就会变为原过期时间减去加锁用时

5、如果失败 手动unlock所有实例

如果有时钟漂移现象需要减去额外的时间 

### 主从同步

#### 全量同步

如果是一个全新的slave需要进行全量的同步，或者`replication id` 和`offset`有错误。

replica**主动**向master发送`sync`命令请求同步，master收到命令后执行`BGSAVE`命令，生成RDB文件，此时新的变化会写入内存缓冲区与旧的RDB文件

当写完以后向replica发送RDB文件，发送完毕以后，发送缓冲区的命令。

#### 增量同步

replica会**主动**向master发送`psync`命令请求同步，其中包含 replication id 和offset，并且是非阻塞的。

master会对比`replication id` 和`offset`,如果没有错误，会发送未发送过的offset数据给replication

#### Replication Id

实际上会有两个`replication id`，当进行master替换或者重启时，会产生新的id。这时候replica 会首先比较旧的id,以避免进行不必要的full sync。然后都替换为使用新的id。设计这个机制的目的主要是为了防止网络分区，会导致同一个id和offest的数据却不一样，违背了一致性保证。

#### 其他

默认情况下replica是只读的，当然也可以设置可写，但是这些数据，会在与master做同步的时候被清除。

### Expire

expire其实是计算一个`unix timestamp`代表过期时间，当对这个key进行查询时如果已经过去则进行删除（惰性删除），另外会有一个子线程做淘汰策略。

expire机制如何在replica上生效的 ？

1、replica不做expire只等待master的`del`命令 

2、本地逻辑时钟，如果对过期key进行读操作会返回不存在，但不会实际去删除

 3、lua脚本执行时，被认为是原子的 概念上时间是暂停的不会进行过期操作

### 持久化

#### RDB

fork一个子进程，写一个新的rdb文件，这时新进来的数据会写在内存缓冲里，当写完旧的文件原子性重命名然后把缓冲里的数据刷进去。

优点：某个时间点的单文件数据集快照，非常紧凑，适合备份；fork一个子进程进行持久化，不会影响父进程；从大文件回复比aof更快

缺点： 容易丢失数据；在执行fork的时候会阻塞，而aof的fork只在rewrite时候进行；

#### AOF

根据aof的策略默认每隔一秒，往aof文件追加执行的命令

优点：更加不容易数据丢失；即使写到一半出现灾难，也可以使用修复工具丢弃错误的几行；

缺点：文件大；需要定期rewrite

rewrite过程:fork一个子进程，开始在一个新的临时文件中写入aof。同时这时候新的数据变化，会同时写入内存缓冲和旧的aof文件中。当子进程写完会把缓冲中的数据再追加到aof文件中。原子性更换文件名，使之指向新的文件	

### 哨兵

作用：监控、提醒、故障转移、配置提供

1、使用gossip protocols（流言协议）来确定 master节点是SDOWN还是ODOWN

2、使用投票协议(agreement protocols、raft算法)来决定是否执行自动故 障迁移

一个哨兵可以监视多个主从系统：

```
sentinel monitor mymaster 127.0.0.1 6380 2（quorum数） 
sentinel monitor othermaster 192.168.88.60 6380 4 
```

通过对主节点发送info命令获取结构拓扑图

当有quorum个sentinel认为master已经fail时即可进行failover，注意quorum只用于发现fail。

然后当有Max(quorum, majority) （其中majority是超过sentinel机器一般的数量）个sentinel投了quorum中的一台sentinel时，这时这台sentinel会作为leader去进行failover。

从replica选出没有disconnected 然后判断slave-priorty replication offset run id 来选出

哨兵本身的自动发现机制是订阅redis的频道来了解其他信息以及对主节点的判断

### 底层数据结构（TODO）

### 为什么那么快（TODO）

## 排序

### 选择排序

> 首先找到数组中的最小元素与第一个元素交换，在剩下的元素中找到最小的元素与第二个元素（即剩下元素中的第一个）交换，以此类推。

代码示例：

```java
public void selectSort(int[] nums) {
    selectMin(nums, 0);
    for (int num : nums) {
        System.out.println(num);
    }
}

private void selectMin(int[] nums, int start) {
    if (start == nums.length - 1) {
        return;
    }

    int index = 0;
    int min = Integer.MAX_VALUE;

    for (int i = start; i < nums.length; i++) {
        if (nums[i] < min) {
            min = nums[i];
            index = i;
        }
    }
    int temp = nums[start];
    nums[start] = nums[index];
    nums[index] = temp;

    selectMin(nums, start + 1);
}
```

时间复杂度显然为`n^2`。

运行时间和输入无关，每轮都需要扫描所有剩下的元素，交换最多只需n次。

### 插入排序

> 和选择排序一样，当前索引左侧的元素是有序的。每次将当前元素插入到左侧正确的位置然后右移指针，当指针移到最右侧则排序完成。

代码示例：

```java
public void insertSort(int[] nums) {

        for (int i = 1;i < nums.length; i++) {

            for(int j = i; j > 0 && nums[j] < nums[j - 1]; j--) {
                int temp = nums[j];
                nums[j] = nums[j - 1];
                nums[j - 1] = temp;
            }
        }
        for (int num : nums) {
            System.out.print(num + ",");
        }
    }
```

时间复杂度平均为`n^2`

运行时间和输入是否部分有序相关。最好情况只需n-1次比较0次交换。

### 希尔排序

> 基于插入排序，核心思想是使数组任意间隔为h的数组有序。使任何从数组索引h开始的元素间隔h有序，h的取值可以为1,4,13,40(3n + 1)

代码示例：

```java
public void shellSort(int[] nums) {

    int h = 1;

    while(3 * h < nums.length) {
        h = 3 * h + 1;
    }

    while (h >= 1) {

        for (int i = h; i < nums.length; i++) {
            for (int j = i; j > 0 && nums[j] < nums[j - 1]; j = j - h) {
                int temp = nums[j];
                nums[j] = nums[j - 1];
                nums[j - 1] = temp;
            }
        }

        h = h / 3;
    }
    for (int num : nums) {
        System.out.print(num + ",");
    }
}
```

时间复杂度不到`n^2`

### 归并排序

> 分治思想，将两个已经排序的子数组合并成一个已经排序的数组。切分到最小后两个子数组各只有一个元素这是天然排序的。然后就可以合并成一个两个元素的已排序数组，一直到所有子数组都被归并

代码示例：

```java
private static  int[] aux;

public void mergeSort(int[] nums) {
    aux = new int[nums.length];

    sort(nums, 0, nums.length - 1);

    for (int num : nums) {
        System.out.print(num + ",");
    }
}

private void sort(int[] nums, int left, int right) {
    if (left >= right) {
        return;
    }

    int mid = left + (right - left)/2;

    sort(nums, left, mid);
    sort(nums, mid + 1, right);
    merge(nums, left, mid, right);
}

private void merge(int[] nums, int left, int mid, int right) {

    for (int i = left; i <= right; i++) {
        aux[i] = nums[i];
    }

    int former = left;
    int latter = mid + 1;

    for (int i = left; i <=right; i++) {
        if (former > mid) {
            nums[i] = aux[latter];
            latter++;
        }else if (latter > right) {
            nums[i] = aux[former];
            former++;
        }else if (aux[former] < aux[latter]) {
            nums[i] = aux[former];
            former++;
        }else {
            nums[i] = aux[latter];
            latter++;
        }
    }
}
```

