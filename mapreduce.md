# MapReduce

> 6.824 lab1 总结

##  一、论文

https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf

## 二、总体流程

### coordinator视角

1. 启动一个coordinator，通过读取现有文件生成一系列待执行的任务，保存在本地数据结构中
2. 启动一个协程定时轮询判断是否所有任务都已经完成
3. 启动一个协程定时轮询是否有超时仍然在进行中的任务，如果有，则将这个任务恢复到未开始状态
4. 提供一个rpc接口用于响应worker的请求，分配服务。判断当前是否还有待分配的map任务
   1. 如果有则分配一个map任务给worker，并设置任务分配时间，将任务状态变为执行中
   2. 如果没有待分配的map任务但还有在进行中的map任务，则响应让worker等待之后在请求
   3. 如果没有待分配的map任务且没有进行中的map任务，如果有待分配的reduce任务，则分配一个reduce任务给worker，并设置任务分配时间，将任务状态变为执行中
   4. 如果没有待分配的map任务且没有进行中的map任务且没有待分配的reduce任务，但有进行中的reduce任务，则响应让worker等待之后在请求
   5. 如果没有待分配的map任务且没有进行中的map任务且没有待分配的reduce任务且没有进行中的reduce任务，则代表所有任务已经完成响应结束
5. 提供一个rpc接口用于响应worker的请求，接受任务完成通知
   1. 如果是map类型任务。删除这个任务，并保存map任务结束后生成的多个文件地址
   2. 如果是reduce类型任务。删除这个任务

### work视角

1. 启动多个worker，不断轮询向coordinate请求任务
   1. 如果响应结束，则代表所有任务都已经结束，则worker也结束
   2. 如果响应等待。则在下一次轮询中继续请求
   3. 如果响应成功，则接受任务开始执行任务
2. 如果是map类型任务
   1. 根据任务传入的**一个**文件地址，进行读取解析
   2. 将读取的内容进行拆分key为单词，value为1代表单词出现了一次
   3. 将key进行hash，再与任务传入的reduce分片数取余
   4. 将上述内容更加计算结果分别写进多个文件。也就是说如果reduce为10的话，本次map任务就会分别写进10个文件
   5. 注意多个map任务会向同一个文件写入，所以注意IO操作方式
   6. 通知coordinate任务成功
3. 如果是reduce类型任务
   1. 根据任务传入的**多个**文件地址，进行读取解析（这个文件里面是map的结果也就是key为单词，value为1）
   2. 将这些数据按照key进行排序
   3. 对同key的数据，其value进行累加，合并数据
   4. 将结果写到一个文件中（即一个reduce任务会输出一个文件）
   5. 通知coordinate任务成功

## 三、细节要点

### 任务数据结构

任务至少要包含以下数据字段

* 唯一ID。用于表示任务，以便worker任务完成通知时coordinate可以进行匹配等场景使用
* 任务类型。Map、Reduce
* 任务状态 。待分配、进行中、已完成
* 任务启动时间。
* reduce分片数字。
* 文件大小
* 文件地址。对于map任务来说是一个文件地址，对于reduce来说是多个文件地址

coordinate至少要包含以下数据字段

* 待分配的Map任务列表
* 进行中的Map任务列表
* 待分配的Reduce任务列表
* 进行中的Reduce任务列表

### 并发安全

由于所有任务都会被并发读写（检查任务状态，改变任务状态等），因此需要加锁保证并发安全。最简单的方式就是粗粒度的对各个方法整体加统一把锁，保证并发时只有一种函数对以上数据结构进行读写

### 幂等性

由于当worker失败时，coordinator会在任务执行超时后进行重新调度，因此需要保证map和reduce的执行是要幂等的。

### 其他

按照论文的要求，还应有以下实现（实验不可考察）：

* map任务中就应该对key先进行排序

* map任务内存数据为周期刷盘

* reduce如果对于接收到文件很大的情况，使用外排序

  

## 四、容错设计

*不考察*

* coordinator与worker之间有心跳包维持，如果worker挂了，所有这个worker上已完成（可选如果是本地文件方案的话，可能也会不可访问）和进行中的任务都要被重新调度。reduce会被重新通知地址

* 为了防止写文件写到一般挂掉，通过先写临时文件，在写完之后再改名的方式进行



## 五、遗留问题

目前的实现是在确保所有Map任务都完成的情况下再执行reduce任务。原因是在设计里，reduce是一次读取所有他要处理的问题然后处理完之后刷盘。

如果要允许Map和Reduce任务并行，在reduce任务可能执行多次。那需要reduce每次写盘之后再接到任务的情况下需要再读取数据重新累加，再覆盖文件。

这里结合上述容错设计，应该拷贝一个临时文件（dirty file）进行操作。

